{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Manipulation in Python with PIL and OpenCV\n",
    "\n",
    "## Overview\n",
    "In this lesson, we will explore image manipulation using two popular Python libraries: PIL (Pillow) and OpenCV. You will learn how to load, display, resize, rotate, and apply basic filters to images using these libraries. Additionally, we will compare the functionality and performance of PIL and OpenCV.\n",
    "\n",
    "By the end of this lesson, you will have a better understanding of how to perform image manipulation tasks programmatically and how to choose between PIL and OpenCV depending on your needs.\n",
    "\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this section, you will:\n",
    "- Understand the importance of selecting appropriate image augmentations for training machine learning models in underwater imagery analysis.\n",
    "- Learn how to apply image transformations such as shearing, cropping, adding noise, and adjusting brightness using **PIL** and **OpenCV**.\n",
    "- Develop a deeper understanding of how augmentations improve model robustness in real-world scenarios, such as handling camera misalignment, murky water conditions, and variable lighting during **AUV surveys**\n",
    "\n",
    "---\n",
    "## The Theory Behind Choosing Augmentations for Training Imagery\n",
    "\n",
    "When training machine learning models, particularly in **highly variable condition** tasks such as underwater image analysis, image augmentation is a powerful tool to improve model robustness and performance. Augmentation creates variations of the training data, allowing models to generalize better to real-world conditions. For example, **shearing** can simulate the effects of camera tilt commonly seen in **AUV surveys**, where slight angles and shifts can distort how objects are captured. By applying shear transformations, we teach models to recognize objects even when they are skewed due to misalignment during transect movement. Another useful augmentation is **cropping**, which mimics scenarios where cameras, such as stationary underwater systems, capture only part of an objectâ€”often seen in situations where fish or coral are cut off at the edges of the frame. Training with cropped images helps models learn to detect partial objects and improves their robustness in handling incomplete data. In murky underwater environments with sediment or low visibility, **adding noise** can replicate the challenge of detecting objects in degraded imagery. Noise simulates particles in the water, preparing models to distinguish features despite visual interference. Similarly, **brightness adjustments** are crucial for dealing with varying lighting conditions that change with depth or time of day. By exposing models to images with different brightness levels, they become more adaptable to fluctuations in light intensity. Additionally, **rotations** help models handle misalignment that occurs naturally in dynamic underwater environments, where cameras may not always be perfectly horizontal. Lastly, **blurring** can simulate motion or water flow, which is useful when image clarity is compromised by movement during data collection. Tailoring these augmentations to the challenges of underwater surveys helps build models that are more adaptable, improving detection accuracy and resilience in diverse conditions. The following sections provide examples of how to implement these augmentations in **PIL** and **OpenCV**.\n",
    "\n",
    ":::{note}\n",
    "The following is meant to be a place for you to come back and reference these crucial augmentations in future activities. \n",
    ":::\n",
    "\n",
    "---\n",
    "\n",
    "## Loading and Displaying Images\n",
    "\n",
    "Before performing any manipulations, we need to load and display images. Both PIL and OpenCV provide easy ways to handle this.\n",
    "\n",
    "### Using PIL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an image using PIL\n",
    "pil_image = Image.open('/path/to/your/image.jpg')\n",
    "\n",
    "# Display the image using matplotlib\n",
    "plt.imshow(pil_image)\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.title(\"Image Loaded with PIL\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenCV:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an image using OpenCV\n",
    "opencv_image = cv2.imread('/path/to/your/image.jpg')\n",
    "\n",
    "# Convert the image from BGR to RGB (OpenCV loads images in BGR by default)\n",
    "opencv_image_rgb = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the image using matplotlib\n",
    "plt.imshow(opencv_image_rgb)\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.title(\"Image Loaded with OpenCV\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing Images\n",
    "\n",
    "Resizing is one of the most common operations when working with images. We will resize images using both PIL and OpenCV.\n",
    "\n",
    "### Using PIL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Resizing an image using PIL\n",
    "pil_resized_image = pil_image.resize((200, 200))  # Resize to 200x200 pixels\n",
    "\n",
    "# Display resized image\n",
    "plt.imshow(pil_resized_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Resized Image using PIL\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenCV:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Resizing an image using OpenCV\n",
    "opencv_resized_image = cv2.resize(opencv_image_rgb, (200, 200))  # Resize to 200x200 pixels\n",
    "\n",
    "# Display resized image\n",
    "plt.imshow(opencv_resized_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Resized Image using OpenCV\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotating Images\n",
    "\n",
    "Rotating images is another common transformation. We can easily rotate images using both PIL and OpenCV.\n",
    "\n",
    "### Using PIL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Rotating an image using PIL\n",
    "pil_rotated_image = pil_image.rotate(45)  # Rotate by 45 degrees\n",
    "\n",
    "# Display rotated image\n",
    "plt.imshow(pil_rotated_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Rotated Image using PIL\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenCV:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Rotating an image using OpenCV\n",
    "# First, we need to define the rotation matrix and apply it to the image\n",
    "(h, w) = opencv_image_rgb.shape[:2]\n",
    "center = (w // 2, h // 2)\n",
    "\n",
    "# Rotate the image by 45 degrees\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center, 45, 1.0)\n",
    "opencv_rotated_image = cv2.warpAffine(opencv_image_rgb, rotation_matrix, (w, h))\n",
    "\n",
    "# Display rotated image\n",
    "plt.imshow(opencv_rotated_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Rotated Image using OpenCV\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Filters\n",
    "\n",
    "Both PIL and OpenCV offer the ability to apply filters to images. We'll demonstrate a simple blur effect.\n",
    "\n",
    "### Using PIL (Gaussian Blur):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFilter\n",
    "\n",
    "# Apply Gaussian Blur using PIL\n",
    "pil_blurred_image = pil_image.filter(ImageFilter.GaussianBlur(5))  # Apply a blur with radius 5\n",
    "\n",
    "# Display blurred image\n",
    "plt.imshow(pil_blurred_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Blurred Image using PIL\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenCV (Gaussian Blur):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Apply Gaussian Blur using OpenCV\n",
    "opencv_blurred_image = cv2.GaussianBlur(opencv_image_rgb, (15, 15), 0)  # Apply a blur with a 15x15 kernel\n",
    "\n",
    "# Display blurred image\n",
    "plt.imshow(opencv_blurred_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Blurred Image using OpenCV\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting Brightness\n",
    "\n",
    "Brightness is a key property of an image that you can manipulate to make an image lighter or darker.\n",
    "\n",
    "### Using PIL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import ImageEnhance\n",
    "\n",
    "# Enhance brightness using PIL\n",
    "enhancer = ImageEnhance.Brightness(pil_image)\n",
    "pil_bright_image = enhancer.enhance(1.5)  # Increase brightness by 50%\n",
    "\n",
    "# Display brightened image\n",
    "plt.imshow(pil_bright_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Brightened Image using PIL\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Increase brightness by scaling pixel values\n",
    "opencv_bright_image = cv2.convertScaleAbs(opencv_image_rgb, alpha=1.2, beta=50)  # Increase brightness\n",
    "\n",
    "# Display brightened image\n",
    "plt.imshow(opencv_bright_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Brightened Image using OpenCV\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shearing Images\n",
    "\n",
    "Shearing is a transformation that slants the shape of an object. We'll shear images using PIL and OpenCV.\n",
    "\n",
    "### Using PIL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import ImageTransform\n",
    "\n",
    "# Create a shear transform matrix\n",
    "shear_matrix = (1, 0.5, 0, 0.5, 1, 0)\n",
    "\n",
    "# Apply shear using PIL\n",
    "pil_sheared_image = pil_image.transform(pil_image.size, ImageTransform.AffineTransform(shear_matrix))\n",
    "\n",
    "# Display sheared image\n",
    "plt.imshow(pil_sheared_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Sheared Image using PIL\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenCV:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Apply shear using OpenCV\n",
    "rows, cols, ch = opencv_image_rgb.shape\n",
    "M = np.float32([[1, 0.5, 0], [0.5, 1, 0]])  # Shearing matrix\n",
    "\n",
    "opencv_sheared_image = cv2.warpAffine(opencv_image_rgb, M, (cols, rows))\n",
    "\n",
    "# Display sheared image\n",
    "plt.imshow(opencv_sheared_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Sheared Image using OpenCV\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flipping Images\n",
    "\n",
    "Flipping an image horizontally or vertically can be useful in data augmentation for machine learning tasks.\n",
    "\n",
    "### Using PIL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Flip an image horizontally using PIL\n",
    "pil_flipped_image = pil_image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "# Display flipped image\n",
    "plt.imshow(pil_flipped_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Flipped Image using PIL\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenCV:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Flip an image horizontally using OpenCV\n",
    "opencv_flipped_image = cv2.flip(opencv_image_rgb, 1)  # 1 for horizontal flipping\n",
    "\n",
    "# Display flipped image\n",
    "plt.imshow(opencv_flipped_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Flipped Image using OpenCV\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping Images\n",
    "\n",
    "Cropping allows you to select a specific region of the image.\n",
    "\n",
    "### Using PIL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Crop a region of the image using PIL\n",
    "left, upper, right, lower = 50, 50, 200, 200\n",
    "pil_cropped_image = pil_image.crop((left, upper, right, lower))\n",
    "\n",
    "# Display cropped image\n",
    "plt.imshow(pil_cropped_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Cropped Image using PIL\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenCV:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Crop a region of the image using OpenCV\n",
    "opencv_cropped_image = opencv_image_rgb[50:200, 50:200]\n",
    "\n",
    "# Display cropped image\n",
    "plt.imshow(opencv_cropped_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Cropped Image using OpenCV\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Images to Grayscale\n",
    "\n",
    "Converting an image to grayscale reduces the number of color channels, which is useful for some computer vision tasks (See next session to learn why that is!)\n",
    "\n",
    "### Using PIL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert image to grayscale using PIL\n",
    "pil_gray_image = pil_image.convert('L')\n",
    "\n",
    "# Display grayscale image\n",
    "plt.imshow(pil_gray_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"Grayscale Image using PIL\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenCV:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert image to grayscale using OpenCV\n",
    "opencv_gray_image = cv2.cvtColor(opencv_image_rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Display grayscale image\n",
    "plt.imshow(opencv_gray_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"Grayscale Image using OpenCV\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Noise to Images\n",
    "\n",
    "Adding random noise to an image can help simulate real-world noise that can be found in murky water, dirty cameras etc. Making it especially useful for training machine learning models.\n",
    "\n",
    "### Using NumPy and PIL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Add random noise to the image using PIL\n",
    "pil_noisy_image = np.array(pil_image).astype(np.float64)\n",
    "noise = np.random.normal(0, 25, pil_noisy_image.shape)\n",
    "pil_noisy_image = np.clip(pil_noisy_image + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Display noisy image\n",
    "plt.imshow(pil_noisy_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Noisy Image using PIL\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenCV:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Add random noise to the image using OpenCV\n",
    "opencv_noisy_image = opencv_image_rgb.astype(np.float64)\n",
    "noise = np.random.normal(0, 25, opencv_noisy_image.shape)\n",
    "opencv_noisy_image = np.clip(opencv_noisy_image + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Display noisy image\n",
    "plt.imshow(opencv_noisy_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Noisy Image using OpenCV\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Histogram Equalization\n",
    "\n",
    "Histogram equalization improves the contrast in images by spreading out the intensity values. Currently this is almost exclusively done using OpenCV.\n",
    "\n",
    "### Using OpenCV:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Apply histogram equalization using OpenCV\n",
    "opencv_gray_image = cv2.cvtColor(opencv_image_rgb, cv2.COLOR_RGB2GRAY)\n",
    "opencv_hist_eq_image = cv2.equalizeHist(opencv_gray_image)\n",
    "\n",
    "# Display equalized image\n",
    "plt.imshow(opencv_hist_eq_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"Histogram Equalized Image using OpenCV\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Edge Detection\n",
    "\n",
    "Detecting edges is useful for object detection and shape analysis. Currently this is almost exclusively done using OpenCV.\n",
    "\n",
    "\n",
    "### Using OpenCV:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Perform edge detection using Canny method in OpenCV\n",
    "opencv_edges = cv2.Canny(opencv_gray_image, 100, 200)\n",
    "\n",
    "# Display edges\n",
    "plt.imshow(opencv_edges, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"Edge Detection using OpenCV\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Blending Two Images\n",
    "\n",
    "Blending combines two images with a specified weight ratio.\n",
    "\n",
    "### Using OpenCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Blend two images using OpenCV\n",
    "# Ensure images are the same size first\n",
    "opencv_image2 = cv2.resize(opencv_image_rgb, (opencv_image_rgb.shape[1], opencv_image_rgb.shape[0]))\n",
    "blended_image = cv2.addWeighted(opencv_image_rgb, 0.7, opencv_image2, 0.3, 0)\n",
    "\n",
    "# Display blended image\n",
    "plt.imshow(blended_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Blended Image using OpenCV\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding\n",
    "\n",
    "Thresholding converts an image to a binary (black-and-white) image by setting a threshold value. Currently this is almost exclusively done using OpenCV\n",
    "\n",
    "### Using OpenCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Apply simple thresholding in OpenCV\n",
    "_, thresholded_image = cv2.threshold(opencv_gray_image, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Display thresholded image\n",
    "plt.imshow(thresholded_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"Thresholded Image using OpenCV\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Transformation\n",
    "\n",
    "Affine transformations include rotation, translation, scaling, and shearing while preserving collinearity.\n",
    "\n",
    "### Using OpenCV:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define the affine transformation matrix\n",
    "rows, cols, ch = opencv_image_rgb.shape\n",
    "src_points = np.float32([[50, 50], [200, 50], [50, 200]])\n",
    "dst_points = np.float32([[10, 100], [200, 50], [100, 250]])\n",
    "affine_matrix = cv2.getAffineTransform(src_points, dst_points)\n",
    "\n",
    "# Apply affine transformation\n",
    "opencv_affine_image = cv2.warpAffine(opencv_image_rgb, affine_matrix, (cols, rows))\n",
    "\n",
    "# Display affine transformed image\n",
    "plt.imshow(opencv_affine_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Affine Transformation using OpenCV\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Space Conversion: BGR to RGB\n",
    "\n",
    "OpenCV loads images in **BGR** (Blue, Green, Red) format by default, whereas most image processing libraries like **Matplotlib** expect images in **RGB** (Red, Green, Blue) format. To ensure the correct color representation when displaying images, you need to convert from BGR to RGB.\n",
    "\n",
    "### Using OpenCV:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert image from BGR to RGB using OpenCV\n",
    "opencv_image_bgr = cv2.imread('path_to_image')  # Load the image in BGR format\n",
    "opencv_image_rgb = cv2.cvtColor(opencv_image_bgr, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "\n",
    "# Display the RGB image\n",
    "plt.imshow(opencv_image_rgb)\n",
    "plt.axis('off')\n",
    "plt.title(\"BGR to RGB Conversion using OpenCV\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
