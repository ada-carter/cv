
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>5. Creating and Augmenting Datasets &#8212; Computer Vision Across Oceanography</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'book/LA2.75';</script>
    <link rel="canonical" href="https://atticus-carter.github.io/cv/book/LA2.75.html" />
    <link rel="icon" href="../_static/fav.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="6. The Math Behind Convolutional Neural Networks (CNNs)" href="LA3.html" />
    <link rel="prev" title="4. Image Manipulation in Python with PIL and OpenCV" href="LA2.5.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Computer Vision Across Oceanography - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Computer Vision Across Oceanography - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapter 1 - Introduction</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="LA1.html">1. Introduction to Ocean Image Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA1.5.html">2. Survey Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA2.html">3. Image Annotation</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA2.5.html">4. Image Manipulation in Python with PIL and OpenCV</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">5. Creating and Augmenting Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA3.html">6. The Math Behind Convolutional Neural Networks (CNNs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA4.html">7. Understanding CV Metrics and Graphs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapter 2 - Computer Vision Development</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="LA5.html">8. Image Classification with Keras</a></li>
<li class="toctree-l1"><a class="reference internal" href="yolorealprime.html">9. Training YOLO Models: A Guide to Understanding Tasks and Modes</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA6.25.html">10. Object Detection with YOLOv8</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA6.26.html">11. Localizing Fathomnet to a new dataset with YOLO</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA6.27.html">12. Pulling Data from Fathomverse</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA7.html">13. Instance Segmentation with Detectron2</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA8.html">14. Keypoint Detection with MediaPipe</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA9.html">15. Object and Multi-Object Tracking with SAM 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA10.html">16. Image Super-Resolution and Enhancement with SRGAN in TensorFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA11.html">17. Self-Supervised Learning for Image Classification with SimCLR in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA12.html">18. Action Recognition and Event Detection in Videos using I3D Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA13.html">19. Anomaly Detection in Images and Videos using Autoencoders and TensorFlow</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapter 3 - Synthesis Project</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="LA14.html">20. Dataset Preparation and Selection</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA15.html">21. Model Selection and Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA16.html">22. Training and Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA17.html">23. Data Visualization and Figure Creation</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA18.html">24. Usecase Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="LA19.html">25. Tying it all together</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/atticus-carter/cv/master?urlpath=tree/book/LA2.75.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/atticus-carter/cv/blob/master/book/LA2.75.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/atticus-carter/cv" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/atticus-carter/cv/edit/main/book/LA2.75.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/atticus-carter/cv/issues/new?title=Issue%20on%20page%20%2Fbook/LA2.75.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/book/LA2.75.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Creating and Augmenting Datasets</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">5.1. Overview</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">5.1.1. Learning Objectives</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rationale-behind-dataset-creation-and-augmentation">5.2. Rationale Behind Dataset Creation and Augmentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-albumentations">5.3. Introduction to Albumentations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-knowing-the-foundations-is-still-important">5.3.1. Why Knowing the Foundations is Still Important</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#useful-albumentations-augmentations-for-marine-data">5.3.2. Useful Albumentations Augmentations for Marine Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#horizontal-and-vertical-flips">5.3.3. Horizontal and Vertical Flips</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-rotations">5.3.4. Random Rotations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#brightness-and-contrast-adjustments">5.3.5. Brightness and Contrast Adjustments</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-blur">5.3.6. Gaussian Blur</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-noise">5.3.7. Gaussian Noise</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-crop">5.3.8. Random Crop</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#shift-scale-rotate">5.3.9. Shift, Scale, Rotate</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-shadow">5.3.10. Random Shadow</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clahe-contrast-limited-adaptive-histogram-equalization">5.3.11. CLAHE (Contrast Limited Adaptive Histogram Equalization)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#resize">5.3.12. Resize</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-splitting-and-ensuring-annotation-integrity">5.4. 2. Dataset Splitting and Ensuring Annotation Integrity</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-splitting-a-dataset-with-associated-annotations">5.4.1. Example: Splitting a Dataset with Associated Annotations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#batch-processing-and-custom-augmentations">5.5. 3. Batch Processing and Custom Augmentations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-batch-augmentations-with-albumentations-opencv-backend">5.5.1. Example: Batch Augmentations with Albumentations (OpenCV backend)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#customizing-augmentations-based-on-task">5.6. 4. Customizing Augmentations Based on Task</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#object-detection">5.6.1. 4.1 Object Detection</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-augmenting-object-detection-data-with-bounding-boxes">5.6.1.1. Example: Augmenting Object Detection Data with Bounding Boxes</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#image-segmentation">5.6.2. 4.2 Image Segmentation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-augmenting-segmentation-data">5.6.2.1. Example: Augmenting Segmentation Data</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#image-classification">5.6.3. 4.3 Image Classification</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-augmenting-image-classification-data">5.6.3.1. Example: Augmenting Image Classification Data</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interactive-activity-augmenting-a-dataset-of-crabs-and-fish">5.7. Interactive Activity: Augmenting a Dataset of Crabs and Fish</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#instructions">5.8. Instructions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#starter-code">5.9. Starter Code</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#extracting-and-loading-images">5.9.1. Extracting and Loading Images</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#now-you-ll-define-an-augmentation-pipeline-to-apply-transformations-choose-augmentations-that-you-think-make-the-most-sense-for-this-dataset">5.9.2. Now, you’ll define an augmentation pipeline to apply transformations. Choose augmentations that you think make the most sense for this dataset.</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="creating-and-augmenting-datasets">
<span id="lesson-5"></span><h1><span class="section-number">5. </span>Creating and Augmenting Datasets<a class="headerlink" href="#creating-and-augmenting-datasets" title="Link to this heading">#</a></h1>
<section id="overview">
<h2><span class="section-number">5.1. </span>Overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h2>
<p>In this lesson, we will focus on building and preparing datasets for deep learning models, discussing the rationale behind dataset creation and augmentation. We will learn how to perform batch processing of images with multiple augmentations, ensure that associated annotation files stay intact during dataset splitting, and how to choose the right augmentation techniques for different use cases. By the end of this lesson, you’ll have the skills to create a robust dataset pipeline.</p>
<section id="learning-objectives">
<h3><span class="section-number">5.1.1. </span>Learning Objectives<a class="headerlink" href="#learning-objectives" title="Link to this heading">#</a></h3>
<p>By the end of this section, you will:</p>
<ul class="simple">
<li><p>Understand the rationale behind building datasets for deep learning, including the importance of augmentations and data splits.</p></li>
<li><p>Learn how to split datasets into training, validation, and test sets while ensuring associated annotation files (e.g., XML, JSON) remain intact.</p></li>
<li><p>Apply <strong>batch processing</strong> techniques to augment large datasets efficiently.</p></li>
<li><p>Customize augmentations based on the specific task, such as object detection, segmentation, or classification.</p></li>
<li><p>Explore and implement augmentations using <strong>Albumentations</strong>, a fast and flexible image augmentation library.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="rationale-behind-dataset-creation-and-augmentation">
<h2><span class="section-number">5.2. </span>Rationale Behind Dataset Creation and Augmentation<a class="headerlink" href="#rationale-behind-dataset-creation-and-augmentation" title="Link to this heading">#</a></h2>
<p>When training deep learning models, the <strong>quality and diversity of your dataset</strong> is critical. Here are a few reasons why augmenting and preparing datasets properly is important:</p>
<ul class="simple">
<li><p><strong>Dataset Variety</strong>: Real-world data is often limited, so augmentations help create variations in the data (rotation, flipping, brightness, etc.) to make models more robust.</p></li>
<li><p><strong>Data Splitting</strong>: Properly splitting the dataset into training, validation, and test sets is important for ensuring that the model generalizes well. Validation sets help tune hyperparameters, while test sets evaluate final performance.</p></li>
<li><p><strong>Task-Specific Requirements</strong>: Depending on the type of task (e.g., image classification vs. object detection), dataset augmentation strategies might differ. Object detection, for example, requires that the bounding box annotations remain consistent with the augmented images.</p></li>
</ul>
</section>
<section id="introduction-to-albumentations">
<h2><span class="section-number">5.3. </span>Introduction to Albumentations<a class="headerlink" href="#introduction-to-albumentations" title="Link to this heading">#</a></h2>
<p>In <strong>LA 2.5</strong>, we explored how to manually apply image augmentations using <strong>PIL</strong> and <strong>OpenCV</strong>. While these foundational skills are critical for understanding how image transformations work, we now introduce <strong>Albumentations</strong>, a high-level image augmentation library designed for speed, simplicity, and flexibility.</p>
<section id="why-knowing-the-foundations-is-still-important">
<h3><span class="section-number">5.3.1. </span>Why Knowing the Foundations is Still Important<a class="headerlink" href="#why-knowing-the-foundations-is-still-important" title="Link to this heading">#</a></h3>
<p>Understanding how image augmentations work at a lower level provides key benefits:</p>
<ol class="arabic simple">
<li><p><strong>Detailed Control</strong>: Manual augmentation techniques using <strong>PIL</strong> or <strong>OpenCV</strong> give you full control over how transformations are applied. This is especially important when handling complex or custom tasks that might not be covered by high-level libraries.</p></li>
<li><p><strong>Customization</strong>: There are situations where highly specific augmentations are needed, such as when working with <strong>custom image formats</strong> or <strong>non-standard data</strong>. Knowing the underlying operations enables you to extend or modify augmentations beyond the capabilities of higher-level tools.</p></li>
<li><p><strong>Better Debugging</strong>: When a model’s performance suffers from specific augmentations, it’s important to know how they work under the hood. Foundational skills help you troubleshoot issues when high-level libraries behave unexpectedly.</p></li>
</ol>
<p>While detailed control is important, for large-scale datasets like those used in marine science (e.g., images from ROVs, underwater drones, or satellite imagery), <strong>Albumentations</strong> provides a faster, more efficient way to perform bulk augmentations. Let’s explore the syntax and key arguments of some Albumentations augmentations that are particularly useful for marine datasets.</p>
</section>
<hr class="docutils" />
<section id="useful-albumentations-augmentations-for-marine-data">
<h3><span class="section-number">5.3.2. </span>Useful Albumentations Augmentations for Marine Data<a class="headerlink" href="#useful-albumentations-augmentations-for-marine-data" title="Link to this heading">#</a></h3>
<p>Below is a list of key augmentations that can be used for marine datasets. Each transformation includes its <strong>syntax</strong>, <strong>arguments</strong>, and use cases.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Albumemtations is often installed as A to avoid the long (and annoying to say) name</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">albumentations</span> <span class="k">as</span> <span class="nn">A</span>
</pre></div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="horizontal-and-vertical-flips">
<h3><span class="section-number">5.3.3. </span>Horizontal and Vertical Flips<a class="headerlink" href="#horizontal-and-vertical-flips" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="o">.</span><span class="n">HorizontalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">A</span><span class="o">.</span><span class="n">VerticalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, ‘p’ is the probability of applying the flip</p>
<p><strong>Use Case</strong>: Flipping helps simulate different orientations of marine animals or objects. For example, mobile animals might be seen from different angles due to movement, and stationary organisms and geologic features can benefit from this augmentation due to variations in camera position. Flipping almost always increase variability, making it a very common augmentation.</p>
</section>
<section id="random-rotations">
<h3><span class="section-number">5.3.4. </span>Random Rotations<a class="headerlink" href="#random-rotations" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="o">.</span><span class="n">Rotate</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, ‘limit’ is the Maximum rotation angle (in degrees) in both directions.’p’ is the probability of applying the rotation.</p>
<p><strong>Use Case</strong>: When marine cameras tilt or rotate due to currents or vehicle movement, applying random rotations can make models more robust to different camera orientations.</p>
</section>
<section id="brightness-and-contrast-adjustments">
<h3><span class="section-number">5.3.5. </span>Brightness and Contrast Adjustments<a class="headerlink" href="#brightness-and-contrast-adjustments" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="o">.</span><span class="n">RandomBrightnessContrast</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, ‘p’ is the probability of applying a random amount of brightness or contrast augmentation</p>
<p><strong>Use Case</strong>: Underwater lighting conditions vary dramatically, especially when working with still cam imagery that has a very bright illuminated foreground and a much darker background.</p>
</section>
<section id="gaussian-blur">
<h3><span class="section-number">5.3.6. </span>Gaussian Blur<a class="headerlink" href="#gaussian-blur" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="o">.</span><span class="n">Blur</span><span class="p">(</span><span class="n">blur_limit</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, ‘blur_limit’ is the maximum kernel size for blurring and ‘p’ is the probability of applying that blur</p>
<p><strong>Use Case</strong>: Blurring can simulate the effect of water turbidity, where visibility is reduced due to particles in the water. This is particularly useful for deep-sea environments or locations with high sediment. This can also be useful when looking at aerial survey data of marine mammals where varying degrees of their bodies are underwater or above water leading to a blur like effect. Similarly diffuse flows in hydrothermal imagery can show up as an intense blur, adding this augmentation is a good idea to catch classes that are partially obstructed by it.</p>
</section>
<section id="gaussian-noise">
<h3><span class="section-number">5.3.7. </span>Gaussian Noise<a class="headerlink" href="#gaussian-noise" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="o">.</span><span class="n">GaussNoise</span><span class="p">(</span><span class="n">var_limit</span><span class="o">=</span><span class="p">(</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">50.0</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, ‘var_limit’ is the range of variance for the noise and ‘p’ is the probability of applying that blur</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>There is no strict upper or lower limit imposed by the function itself; it’s based on the range you define. However, extremely large variance values might lead to very noisy and potentially unusable images. For that reason its good to stick to something like 10-50</p>
</div>
<p><strong>Use Case</strong>: Similar to Gaussian blur, adding Gaussian noise simulates image degradation in murky waters or low-light environments. This is important for creating a more realistic training dataset in challenging underwater conditions.</p>
</section>
<section id="random-crop">
<h3><span class="section-number">5.3.8. </span>Random Crop<a class="headerlink" href="#random-crop" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, Width and Height are self explanotory and given in pixel value, and ‘p’ is the probability of applying the crop</p>
<p><strong>Use Case</strong>: Random cropping can simulate the loss of image data, helping the model learn to focus on partial objects or areas. This is especially useful when the camera cannot capture the entire object due to occlusion or framing issues.</p>
</section>
<section id="shift-scale-rotate">
<h3><span class="section-number">5.3.9. </span>Shift, Scale, Rotate<a class="headerlink" href="#shift-scale-rotate" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="o">.</span><span class="n">ShiftScaleRotate</span><span class="p">(</span><span class="n">shift_limit</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">scale_limit</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">rotate_limit</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, ‘shift_limit’ controls the maximum shift as a fraction of image size, ‘scale_limit’ is the maximum scaling factor, ‘rotate_limit’ is the maximum rotation angle in degrees, and ‘p’ is the probability of applying the transformation.</p>
<p><strong>Use Case</strong>: This augmentation is useful for simulating camera movement underwater, where slight shifts and rotations occur due to currents or vehicle navigation. Scaling can help the model handle different sizes of objects, and shifting ensures robustness against changes in object placement.</p>
</section>
<section id="random-shadow">
<h3><span class="section-number">5.3.10. </span>Random Shadow<a class="headerlink" href="#random-shadow" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="o">.</span><span class="n">RandomShadow</span><span class="p">(</span><span class="n">shadow_roi</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">num_shadows_lower</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_shadows_upper</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">shadow_dimension</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, ‘shadow_roi’ is the region of interest for placing shadows (coordinates as a fraction of the image size), ‘num_shadows_lower’ and ‘num_shadows_upper’ control the range for the number of shadows, ‘shadow_dimension’ determines the size of the shadow, and ‘p’ is the probability of applying the shadow.</p>
<p><strong>Use Case</strong>: This augmentation can simulate shadows caused by marine structures, plants, or large marine animals. Shadows can introduce varying light conditions, making the model more resilient to different lighting situations in real-world environments.</p>
</section>
<section id="clahe-contrast-limited-adaptive-histogram-equalization">
<h3><span class="section-number">5.3.11. </span>CLAHE (Contrast Limited Adaptive Histogram Equalization)<a class="headerlink" href="#clahe-contrast-limited-adaptive-histogram-equalization" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="o">.</span><span class="n">CLAHE</span><span class="p">(</span><span class="n">clip_limit</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span> <span class="n">tile_grid_size</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, ‘clip_limit’ is the threshold for contrast limiting, ‘tile_grid_size’ is the size of the grid for histogram equalization, and ‘p’ is the probability of applying the augmentation.</p>
<p><strong>Use Case</strong>: CLAHE is useful for improving image contrast in underwater environments where lighting can be uneven or dim. It enhances details that may otherwise be missed, particularly in images with low contrast, such as deep-sea or low-light environments.</p>
</section>
<section id="resize">
<h3><span class="section-number">5.3.12. </span>Resize<a class="headerlink" href="#resize" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">height</span><span class="o">=</span><span class="mi">180</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">180</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, ‘height’ and ‘width’ specify the target dimensions of the image, and ‘p’ is the probability of applying the resize (usually set to 1.0 to ensure resizing is applied to every image).</p>
<p><strong>Use Case</strong>: This ensures that all images are resized to a standard size, such as 180x180, making them consistent for training in deep learning models. Resizing is often necessary when working with images of varying resolutions, particularly in datasets with mixed sources like drone imagery or satellite images.</p>
</section>
</section>
<hr class="docutils" />
<section id="dataset-splitting-and-ensuring-annotation-integrity">
<h2><span class="section-number">5.4. </span>2. Dataset Splitting and Ensuring Annotation Integrity<a class="headerlink" href="#dataset-splitting-and-ensuring-annotation-integrity" title="Link to this heading">#</a></h2>
<p>When splitting a dataset, it’s important to ensure that the associated annotation files (such as <strong>bounding boxes</strong> for object detection or <strong>segmentation masks</strong>) remain aligned with the correct images after augmentation and splitting. Common dataset splits include:</p>
<ul class="simple">
<li><p><strong>Training set</strong>: Typically 70-80% of the data.</p></li>
<li><p><strong>Validation set</strong>: Typically 10-15% of the data for tuning the model.</p></li>
<li><p><strong>Test set</strong>: The final 10-15% for evaluating model performance.</p></li>
</ul>
<section id="example-splitting-a-dataset-with-associated-annotations">
<h3><span class="section-number">5.4.1. </span>Example: Splitting a Dataset with Associated Annotations<a class="headerlink" href="#example-splitting-a-dataset-with-associated-annotations" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Directory paths</span>
<span class="n">image_dir</span> <span class="o">=</span> <span class="s1">&#39;/path/to/images&#39;</span>
<span class="n">annotation_dir</span> <span class="o">=</span> <span class="s1">&#39;/path/to/annotations&#39;</span>
<span class="n">train_dir</span> <span class="o">=</span> <span class="s1">&#39;/path/to/train&#39;</span>
<span class="n">val_dir</span> <span class="o">=</span> <span class="s1">&#39;/path/to/val&#39;</span>
<span class="n">test_dir</span> <span class="o">=</span> <span class="s1">&#39;/path/to/test&#39;</span>

<span class="c1"># Get image files</span>
<span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">image_dir</span><span class="p">)</span> <span class="k">if</span> <span class="n">f</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;.png&#39;</span><span class="p">)]</span>  <span class="c1"># Change extension as needed</span>

<span class="c1"># Split dataset into training, validation, and test sets</span>
<span class="n">train_images</span><span class="p">,</span> <span class="n">val_test_images</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">val_images</span><span class="p">,</span> <span class="n">test_images</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">val_test_images</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Move images and their annotations to respective folders</span>
<span class="k">def</span> <span class="nf">move_files</span><span class="p">(</span><span class="n">image_list</span><span class="p">,</span> <span class="n">target_dir</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">image_list</span><span class="p">:</span>
        <span class="c1"># Move image</span>
        <span class="n">shutil</span><span class="o">.</span><span class="n">move</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">image_dir</span><span class="p">,</span> <span class="n">image</span><span class="p">),</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_dir</span><span class="p">,</span> <span class="s1">&#39;images&#39;</span><span class="p">,</span> <span class="n">image</span><span class="p">))</span>
        
        <span class="c1"># Move associated annotation (assumes annotation has the same name but different extension)</span>
        <span class="n">annotation_file</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.png&#39;</span><span class="p">,</span> <span class="s1">&#39;.xml&#39;</span><span class="p">)</span>  <span class="c1"># Adjust extension based on annotation type</span>
        <span class="n">shutil</span><span class="o">.</span><span class="n">move</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">annotation_dir</span><span class="p">,</span> <span class="n">annotation_file</span><span class="p">),</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_dir</span><span class="p">,</span> <span class="s1">&#39;annotations&#39;</span><span class="p">,</span> <span class="n">annotation_file</span><span class="p">))</span>

<span class="c1"># Move the split files</span>
<span class="n">move_files</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_dir</span><span class="p">)</span>
<span class="n">move_files</span><span class="p">(</span><span class="n">val_images</span><span class="p">,</span> <span class="n">val_dir</span><span class="p">)</span>
<span class="n">move_files</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="batch-processing-and-custom-augmentations">
<h2><span class="section-number">5.5. </span>3. Batch Processing and Custom Augmentations<a class="headerlink" href="#batch-processing-and-custom-augmentations" title="Link to this heading">#</a></h2>
<p>Once the dataset is split, you can apply <strong>batch augmentations</strong> to increase the diversity of the dataset. Depending on the task (classification, object detection, segmentation), certain augmentations may be more appropriate than others.</p>
<section id="example-batch-augmentations-with-albumentations-opencv-backend">
<h3><span class="section-number">5.5.1. </span>Example: Batch Augmentations with Albumentations (OpenCV backend)<a class="headerlink" href="#example-batch-augmentations-with-albumentations-opencv-backend" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">albumentations</span> <span class="k">as</span> <span class="nn">A</span>
<span class="kn">from</span> <span class="nn">albumentations.pytorch</span> <span class="kn">import</span> <span class="n">ToTensorV2</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># Define augmentation pipeline</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">A</span><span class="o">.</span><span class="n">HorizontalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">A</span><span class="o">.</span><span class="n">Rotate</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.7</span><span class="p">),</span>
    <span class="n">A</span><span class="o">.</span><span class="n">RandomBrightnessContrast</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">),</span>
    <span class="n">A</span><span class="o">.</span><span class="n">ShiftScaleRotate</span><span class="p">(</span><span class="n">shift_limit</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">scale_limit</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">rotate_limit</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">A</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">128</span><span class="p">),</span>
    <span class="n">A</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">)),</span>
    <span class="n">ToTensorV2</span><span class="p">(),</span>
<span class="p">])</span>

<span class="c1"># Batch process images in a folder</span>
<span class="n">input_dir</span> <span class="o">=</span> <span class="s1">&#39;/path/to/train/images&#39;</span>
<span class="n">output_dir</span> <span class="o">=</span> <span class="s1">&#39;/path/to/augmented/images&#39;</span>

<span class="k">def</span> <span class="nf">augment_images</span><span class="p">(</span><span class="n">input_dir</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">,</span> <span class="n">transform</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">output_dir</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">image_file</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">input_dir</span><span class="p">):</span>
        <span class="n">image_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">input_dir</span><span class="p">,</span> <span class="n">image_file</span><span class="p">)</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
        
        <span class="c1"># Apply augmentation</span>
        <span class="n">augmented</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">)[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span>
        
        <span class="c1"># Save augmented image</span>
        <span class="n">output_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">image_file</span><span class="p">)</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">augmented</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="mi">255</span><span class="p">)</span>  <span class="c1"># Convert back to original range</span>

<span class="n">augment_images</span><span class="p">(</span><span class="n">input_dir</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">,</span> <span class="n">transform</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In this example, we use <strong>Albumentations</strong>, a fast and flexible image augmentation library, to apply various transformations to batches of images. The augmentation pipeline includes horizontal flipping, random rotations, brightness and contrast adjustments, and random cropping.</p>
</section>
</section>
<hr class="docutils" />
<section id="customizing-augmentations-based-on-task">
<h2><span class="section-number">5.6. </span>4. Customizing Augmentations Based on Task<a class="headerlink" href="#customizing-augmentations-based-on-task" title="Link to this heading">#</a></h2>
<p>Different computer vision tasks require specific augmentations. Here are some augmentation strategies for common tasks:</p>
<section id="object-detection">
<h3><span class="section-number">5.6.1. </span>4.1 Object Detection<a class="headerlink" href="#object-detection" title="Link to this heading">#</a></h3>
<p>When working on object detection tasks, it’s important to ensure that the <strong>bounding boxes</strong> are adjusted appropriately with the image augmentations.</p>
<section id="example-augmenting-object-detection-data-with-bounding-boxes">
<h4><span class="section-number">5.6.1.1. </span>Example: Augmenting Object Detection Data with Bounding Boxes<a class="headerlink" href="#example-augmenting-object-detection-data-with-bounding-boxes" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">transform</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">A</span><span class="o">.</span><span class="n">HorizontalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">A</span><span class="o">.</span><span class="n">RandomBrightnessContrast</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">),</span>
    <span class="n">A</span><span class="o">.</span><span class="n">Rotate</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.7</span><span class="p">),</span>
<span class="p">],</span> <span class="n">bbox_params</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">BboxParams</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s1">&#39;pascal_voc&#39;</span><span class="p">,</span> <span class="n">label_fields</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;class_labels&#39;</span><span class="p">]))</span>

<span class="c1"># Example of augmenting an image with a bounding box</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;/path/to/image.png&#39;</span><span class="p">)</span>
<span class="n">bboxes</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">250</span><span class="p">]]</span>  <span class="c1"># Example bounding box in PASCAL VOC format</span>
<span class="n">class_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;crab&#39;</span><span class="p">]</span>

<span class="c1"># Apply the augmentations</span>
<span class="n">augmented</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">bboxes</span><span class="o">=</span><span class="n">bboxes</span><span class="p">,</span> <span class="n">class_labels</span><span class="o">=</span><span class="n">class_labels</span><span class="p">)</span>
<span class="n">aug_image</span> <span class="o">=</span> <span class="n">augmented</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span>
<span class="n">aug_bboxes</span> <span class="o">=</span> <span class="n">augmented</span><span class="p">[</span><span class="s1">&#39;bboxes&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Here, <strong>Albumentations</strong> ensures that bounding boxes are modified along with the image, keeping the spatial relationships intact. The <code class="docutils literal notranslate"><span class="pre">bbox_params</span></code> argument specifies that we are using Pascal VOC format for bounding boxes.</p>
</section>
</section>
<section id="image-segmentation">
<h3><span class="section-number">5.6.2. </span>4.2 Image Segmentation<a class="headerlink" href="#image-segmentation" title="Link to this heading">#</a></h3>
<p>For segmentation tasks, it’s crucial that <strong>segmentation masks</strong> undergo the same augmentations as the corresponding images.</p>
<section id="example-augmenting-segmentation-data">
<h4><span class="section-number">5.6.2.1. </span>Example: Augmenting Segmentation Data<a class="headerlink" href="#example-augmenting-segmentation-data" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">transform</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">A</span><span class="o">.</span><span class="n">HorizontalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">A</span><span class="o">.</span><span class="n">Rotate</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.7</span><span class="p">),</span>
    <span class="n">A</span><span class="o">.</span><span class="n">RandomBrightnessContrast</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">),</span>
<span class="p">])</span>

<span class="c1"># Augment both image and mask</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;/path/to/image.png&#39;</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;/path/to/mask.png&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># Load mask as grayscale</span>

<span class="c1"># Apply the augmentations to both image and mask</span>
<span class="n">augmented</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
<span class="n">aug_image</span> <span class="o">=</span> <span class="n">augmented</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span>
<span class="n">aug_mask</span> <span class="o">=</span> <span class="n">augmented</span><span class="p">[</span><span class="s1">&#39;mask&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>In this case, both the image and its corresponding segmentation mask are augmented together to ensure that the mask still matches the transformed image.</p>
</section>
</section>
<section id="image-classification">
<h3><span class="section-number">5.6.3. </span>4.3 Image Classification<a class="headerlink" href="#image-classification" title="Link to this heading">#</a></h3>
<p>For classification tasks, standard augmentations like <strong>random cropping</strong>, <strong>flipping</strong>, and <strong>brightness/contrast adjustments</strong> are useful to improve model generalization.</p>
<section id="example-augmenting-image-classification-data">
<h4><span class="section-number">5.6.3.1. </span>Example: Augmenting Image Classification Data<a class="headerlink" href="#example-augmenting-image-classification-data" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">transform</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">A</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">128</span><span class="p">),</span>
    <span class="n">A</span><span class="o">.</span><span class="n">HorizontalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">A</span><span class="o">.</span><span class="n">RandomBrightnessContrast</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">),</span>
    <span class="n">A</span><span class="o">.</span><span class="n">Rotate</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.7</span><span class="p">),</span>
<span class="p">])</span>

<span class="c1"># Apply augmentations to the image</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;/path/to/image.png&#39;</span><span class="p">)</span>
<span class="n">aug_image</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">)[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span>

<span class="c1"># Save augmented image</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="s1">&#39;/path/to/augmented_image.png&#39;</span><span class="p">,</span> <span class="n">aug_image</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>For classification tasks, augmentations focus on changing the appearance and orientation of the image to help the model learn diverse features.</p>
</section>
</section>
</section>
<hr class="docutils" />
<section id="interactive-activity-augmenting-a-dataset-of-crabs-and-fish">
<h2><span class="section-number">5.7. </span>Interactive Activity: Augmenting a Dataset of Crabs and Fish<a class="headerlink" href="#interactive-activity-augmenting-a-dataset-of-crabs-and-fish" title="Link to this heading">#</a></h2>
<p>In this activity, you will create an augmented dataset using <strong>randomcrab.zip</strong> and <strong>randomfish.zip</strong>. Each ZIP file contains 35 images (180x180 pixels) of crabs and fish, respectively. Your task is to use image augmentations to expand the dataset to <strong>400 images of crabs</strong> and <strong>400 images of fish</strong>, ensuring the output images maintain the same file size (180x180) and keep the original file names.</p>
<p>You’ll be provided with starter code that loads the images and applies basic augmentations. Your job is to customize the augmentation pipeline and generate the augmented images.</p>
</section>
<hr class="docutils" />
<section id="instructions">
<h2><span class="section-number">5.8. </span>Instructions<a class="headerlink" href="#instructions" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Download and extract the ZIP files</strong>:</p>
<ul class="simple">
<li><p><strong>randomcrab.zip</strong> contains 35 images of crabs.</p>
<ul>
<li><p><a class="reference internal" href="#./assets/randomcrab.zip"><span class="xref myst">Download randomcrab.zip</span></a></p></li>
</ul>
</li>
<li><p><strong>randomfish.zip</strong> contains 35 images of fish.</p>
<ul>
<li><p><a class="reference internal" href="#./assets/randomfish.zip"><span class="xref myst">Download randomfish.zip</span></a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Augment each dataset</strong>: Your goal is to generate a total of <strong>400 images</strong> for each class (crabs and fish) by applying various transformations (rotation, brightness, flips, etc.).</p></li>
<li><p><strong>Ensure consistency</strong>: Each output image must:</p>
<ul class="simple">
<li><p>Retain its original file name.</p></li>
<li><p>Be the same size as the original (180x180).</p></li>
</ul>
</li>
<li><p><strong>Save the augmented images</strong> in a directory called <strong>augmented_data/crabs</strong> for crabs and <strong>augmented_data/fish</strong> for fish.</p></li>
</ol>
</section>
<hr class="docutils" />
<section id="starter-code">
<h2><span class="section-number">5.9. </span>Starter Code<a class="headerlink" href="#starter-code" title="Link to this heading">#</a></h2>
<section id="extracting-and-loading-images">
<h3><span class="section-number">5.9.1. </span>Extracting and Loading Images<a class="headerlink" href="#extracting-and-loading-images" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">zipfile</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">albumentations</span> <span class="k">as</span> <span class="nn">A</span>

<span class="c1"># Paths to the ZIP files</span>
<span class="n">crab_zip</span> <span class="o">=</span> <span class="s1">&#39;randomcrab.zip&#39;</span>
<span class="n">fish_zip</span> <span class="o">=</span> <span class="s1">&#39;randomfish.zip&#39;</span>

<span class="c1"># Extract ZIP files</span>
<span class="k">def</span> <span class="nf">extract_zip</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">extract_path</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
        <span class="n">zip_ref</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">extract_path</span><span class="p">)</span>

<span class="c1"># Extract the crab and fish images</span>
<span class="n">extract_zip</span><span class="p">(</span><span class="n">crab_zip</span><span class="p">,</span> <span class="s1">&#39;crabs/&#39;</span><span class="p">)</span>
<span class="n">extract_zip</span><span class="p">(</span><span class="n">fish_zip</span><span class="p">,</span> <span class="s1">&#39;fish/&#39;</span><span class="p">)</span>

<span class="c1"># Load the images</span>
<span class="n">crab_images</span> <span class="o">=</span> <span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;crabs/&#39;</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;crabs/&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="n">f</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;.png&#39;</span><span class="p">)]</span>
<span class="n">fish_images</span> <span class="o">=</span> <span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;fish/&#39;</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;fish/&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="n">f</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;.png&#39;</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="now-you-ll-define-an-augmentation-pipeline-to-apply-transformations-choose-augmentations-that-you-think-make-the-most-sense-for-this-dataset">
<h3><span class="section-number">5.9.2. </span>Now, you’ll define an augmentation pipeline to apply transformations. Choose augmentations that you think make the most sense for this dataset.<a class="headerlink" href="#now-you-ll-define-an-augmentation-pipeline-to-apply-transformations-choose-augmentations-that-you-think-make-the-most-sense-for-this-dataset" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the augmentation pipeline</span>
<span class="n">augmentations</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
<span class="c1">#    A.HorizontalFlip(p=0.5),</span>
<span class="c1">#    A.Rotate(limit=30, p=0.7),</span>

<span class="p">])</span>

<span class="c1"># Create the output directories</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s1">&#39;augmented_data/crabs&#39;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s1">&#39;augmented_data/fish&#39;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="c1"># Function to apply augmentations and save images</span>
<span class="k">def</span> <span class="nf">augment_and_save</span><span class="p">(</span><span class="n">image_path</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">):</span>
    <span class="c1"># Read the image</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
    
    <span class="c1"># Apply augmentations</span>
    <span class="n">augmented</span> <span class="o">=</span> <span class="n">augmentations</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">)[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span>
    
    <span class="c1"># Get the base filename (e.g., &#39;1.png&#39;)</span>
    <span class="n">base_filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
    
    <span class="c1"># Save the augmented image to the output directory</span>
    <span class="n">output_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">base_filename</span><span class="p">)</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">augmented</span><span class="p">)</span>

<span class="c1"># Apply augmentations to crab images</span>
<span class="k">for</span> <span class="n">crab_image</span> <span class="ow">in</span> <span class="n">crab_images</span><span class="p">:</span>
    <span class="n">augment_and_save</span><span class="p">(</span><span class="n">crab_image</span><span class="p">,</span> <span class="s1">&#39;augmented_data/crabs&#39;</span><span class="p">)</span>

<span class="c1"># Apply augmentations to fish images</span>
<span class="k">for</span> <span class="n">fish_image</span> <span class="ow">in</span> <span class="n">fish_images</span><span class="p">:</span>
    <span class="n">augment_and_save</span><span class="p">(</span><span class="n">fish_image</span><span class="p">,</span> <span class="s1">&#39;augmented_data/fish&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./book"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="LA2.5.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Image Manipulation in Python with PIL and OpenCV</p>
      </div>
    </a>
    <a class="right-next"
       href="LA3.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">6. </span>The Math Behind Convolutional Neural Networks (CNNs)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">5.1. Overview</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">5.1.1. Learning Objectives</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rationale-behind-dataset-creation-and-augmentation">5.2. Rationale Behind Dataset Creation and Augmentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-albumentations">5.3. Introduction to Albumentations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-knowing-the-foundations-is-still-important">5.3.1. Why Knowing the Foundations is Still Important</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#useful-albumentations-augmentations-for-marine-data">5.3.2. Useful Albumentations Augmentations for Marine Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#horizontal-and-vertical-flips">5.3.3. Horizontal and Vertical Flips</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-rotations">5.3.4. Random Rotations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#brightness-and-contrast-adjustments">5.3.5. Brightness and Contrast Adjustments</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-blur">5.3.6. Gaussian Blur</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-noise">5.3.7. Gaussian Noise</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-crop">5.3.8. Random Crop</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#shift-scale-rotate">5.3.9. Shift, Scale, Rotate</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-shadow">5.3.10. Random Shadow</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clahe-contrast-limited-adaptive-histogram-equalization">5.3.11. CLAHE (Contrast Limited Adaptive Histogram Equalization)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#resize">5.3.12. Resize</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-splitting-and-ensuring-annotation-integrity">5.4. 2. Dataset Splitting and Ensuring Annotation Integrity</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-splitting-a-dataset-with-associated-annotations">5.4.1. Example: Splitting a Dataset with Associated Annotations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#batch-processing-and-custom-augmentations">5.5. 3. Batch Processing and Custom Augmentations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-batch-augmentations-with-albumentations-opencv-backend">5.5.1. Example: Batch Augmentations with Albumentations (OpenCV backend)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#customizing-augmentations-based-on-task">5.6. 4. Customizing Augmentations Based on Task</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#object-detection">5.6.1. 4.1 Object Detection</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-augmenting-object-detection-data-with-bounding-boxes">5.6.1.1. Example: Augmenting Object Detection Data with Bounding Boxes</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#image-segmentation">5.6.2. 4.2 Image Segmentation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-augmenting-segmentation-data">5.6.2.1. Example: Augmenting Segmentation Data</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#image-classification">5.6.3. 4.3 Image Classification</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-augmenting-image-classification-data">5.6.3.1. Example: Augmenting Image Classification Data</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interactive-activity-augmenting-a-dataset-of-crabs-and-fish">5.7. Interactive Activity: Augmenting a Dataset of Crabs and Fish</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#instructions">5.8. Instructions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#starter-code">5.9. Starter Code</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#extracting-and-loading-images">5.9.1. Extracting and Loading Images</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#now-you-ll-define-an-augmentation-pipeline-to-apply-transformations-choose-augmentations-that-you-think-make-the-most-sense-for-this-dataset">5.9.2. Now, you’ll define an augmentation pipeline to apply transformations. Choose augmentations that you think make the most sense for this dataset.</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Atticus Carter
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>