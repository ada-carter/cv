{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(lesson-11)=\n",
        "# Object Detection with YOLOv8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Overview\n",
        "In this lesson, we will train an Object Detection model using YOLOv8. You'll be able to choose specific augmentations, batch size, resolution, and other parameters based on your system's capabilities and runtime. The dataset is already provided in YOLO format and will be used to train and evaluate the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Learning Objectives\n",
        "By the end of this section, you will:\n",
        "- Understand the YOLO format and how to train a custom object detection model using YOLOv8.\n",
        "- Experiment with different augmentations and hyperparameters for object detection.\n",
        "- Evaluate the model's performance and visualize the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Downloading the Dataset\n",
        "The dataset for this lesson is already formatted in YOLO format. You can load it directly for training and evaluation. Ensure you have the dataset uploaded before proceeding.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparing the Environment\n",
        "Let's first install the required libraries and set up the environment to train our YOLOv8 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install the required dependencies\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "import json\n",
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading the Dataset\n",
        "You can either load your dataset with or without augmentations. The dataset is in YOLO format, which includes images and annotation files with bounding box information.\n",
        "\n",
        "If you have chosen a different dataset or format, ensure it follows YOLO formatting. For this lesson, we assume that the dataset is organized in `train/`, `val/`, and `test/` directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set paths to the dataset\n",
        "zip_file_path = '/content/TeachingTankPlastic.zip'\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/TeachingTankPlastic')\n",
        "\n",
        "# Set the dataset path\n",
        "dataset_path = '/content/TeachingTankPlastic'\n",
        "\n",
        "# Verify the dataset path\n",
        "print(f\"Dataset path is set to: {dataset_path}\")\n",
        "print(f\"Files in dataset path: {os.listdir(dataset_path)}\")\n",
        "\n",
        "# Set train and val paths\n",
        "train_path = os.path.join(dataset_path, 'train/')\n",
        "val_path = os.path.join(dataset_path, 'val/')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b870c7b0",
      "metadata": {},
      "source": [
        "### Create Dataset Configuration File\n",
        "\n",
        "Copy the code cell below to create a configuration file (`teaching_tank_data.yaml`) for your dataset. This configuration file is essential for training YOLO models because it provides a structured way for YOLO to understand the paths to your training, validation, and (optionally) test datasets, as well as the class information. The configuration file tells YOLO where to find the data it needs and how many classes it should expect, which ensures that the training process runs smoothly.\n",
        "\n",
        "Without a properly configured YAML file, YOLO would not know where the datasets are located or how to interpret the classes, leading to errors or failed training. Most of the time this will be generated with your annotation software, however it is important to double check and understand how this file works.\n",
        "\n",
        "The configuration file includes:\n",
        "- Paths to **training**, **validation**, and optionally **test** datasets.\n",
        "- **Number of classes (`nc`)**: This tells YOLO how many unique classes there are to predict.\n",
        "- **Class names (`names`)**: A list of class labels to ensure correct mapping during training and evaluation.\n",
        "\n",
        "Below, you can find the cell to generate the configuration file:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70569be3",
      "metadata": {},
      "outputs": [],
      "source": [
        "train: /content/TeachingTankPlastic/train/images \n",
        "val: /content/TeachingTankPlastic/valid/images    \n",
        "test: /content/TeachingTankPlastic/test/images    \n",
        "nc: 15  # Number of classes\n",
        "\n",
        "names: \n",
        "  - 'Black Plastic Cap'\n",
        "  - 'Blue Nitrile Glove'\n",
        "  - 'Blue Plastic Cap'\n",
        "  - 'Brown Multilayer Plastic'\n",
        "  - 'Green Plastic Cap'\n",
        "  - 'Orange Plastic Cap'\n",
        "  - 'Plastic Bottle'\n",
        "  - 'Purple Insulation Foam'\n",
        "  - 'Purple Multilayer Plastic Bag'\n",
        "  - 'Red - Orange BOPP Bag'\n",
        "  - 'Red Cap'\n",
        "  - 'Red Netting'\n",
        "  - 'Red Plastic Straw'\n",
        "  - 'Yellow Foam'\n",
        "  - 'Yellow Rope'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Customizing Augmentations and Parameters\n",
        "\n",
        "With YOLOv8, applying augmentations during both dataset creation and training is highly beneficial. During the dataset creation phase, some augmentations are universal and should be applied regardless of what the model will be used for. For instance, basic transformations like random flips, rotations, and brightness adjustments help ensure the model can handle general variations found in real-world data. These augmentations provide a strong foundation by improving the model's ability to generalize and reduce the risk of overfitting.\n",
        "\n",
        "However, during the training phase, more specific augmentations can be customized to anticipate particular challenges. For example, if your model is going to be deployed using a new AUV camera system that captures images at an oblique angle, or if it needs to perform well in a survey area with particularly dark conditions, adding targeted augmentations during training will make the model more robust to these conditions. By simulating real-world variability, the model becomes more resilient and adaptable to different scenarios.\n",
        "\n",
        "In addition to augmentations, there are many parameters and arguments that you can pass to your model during training to further refine its performance. These include aspects like learning rate, batch size, optimizer, and more. The ability to customize these parameters allows you to tailor the training process to fit the specific requirements and challenges of your dataset. Ultimately, applying both general and scenario-specific augmentations, along with thoughtful parameter tuning, can significantly enhance your model's adaptability and performance in real-world situations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training the YOLOv8 Model\n",
        "Now that the environment is set up, and you have selected your augmentations and other parameters, we will proceed with training the YOLOv8 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model (pretrained on COCO dataset)\n",
        "model = YOLO('yolov8n.pt')  # You can change this to another YOLOv8 model if needed\n",
        "\n",
        "# Path to the dataset configuration YAML file\n",
        "dataset_config = '/content/TeachingTankPlastic/teaching_tank_data.yaml'  # Path to the YAML file, not the directory\n",
        "\n",
        "# Train the model\n",
        "results = model.train(\n",
        "    data=dataset_config,  # Pass the path to the YAML file\n",
        "    epochs=100,\n",
        "    batch=-1,\n",
        "    imgsz=640,\n",
        "    plots=True\n",
        "\n",
        "    # Add more augmentations and parameters here! \n",
        "    # Check out the Ultralytics documentation to see \n",
        "    # what is available.\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10d574a7",
      "metadata": {},
      "source": [
        "It is important to note that parameters do not have to be passed from a variable and can be directly loaded in during your training script. I purposely set up the dataset_config here so we can check out its contents. Similarly, when choosing your model, you can use a checkpoint to resume training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluating the Model\n",
        "After training, we will evaluate the model performance using validation data and calculate metrics such as mean Average Precision (mAP)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model on the validation dataset\n",
        "metrics = model.val(data=val_path)\n",
        "print(json.dumps(metrics, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Results\n",
        "It is essential to visualize the results on some test images to check how well the model is performing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions on test images\n",
        "test_img = os.path.join(dataset_path, 'test/', 'test_image.jpg')  # Specify a test image\n",
        "results = model.predict(source=test_img, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Activity: Reflecting on Results\n",
        "Now that you've trained and evaluated your model, reflect on the following questions:\n",
        "\n",
        "- How did the augmentations and parameters affect the model's performance?\n",
        "- Were there any significant differences in the mAP metrics for different classes?\n",
        "- What visual observations can you make from the test results?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
