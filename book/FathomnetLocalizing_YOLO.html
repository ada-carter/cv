

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>16. Localizing FathomNet to a New Dataset Using YOLOv11 &#8212; Computer Vision Across Oceanography</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'book/FathomnetLocalizing_YOLO';</script>
    <link rel="canonical" href="https://atticus-carter.github.io/cv/book/FathomnetLocalizing_YOLO.html" />
    <link rel="shortcut icon" href="../_static/fav.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="17. Pulling Data from Fathomnet" href="FathomnetPullingData_YOLO.html" />
    <link rel="prev" title="15. Introduction to FathomNet" href="Introduction_Fathomnet.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Computer Vision Across Oceanography - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Computer Vision Across Oceanography - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Preface</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Landing.html">Welcome to Computer Vision Across the Marine Sciences</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tools.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="License_Page.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="Acknowledgements.html">Acknowledgements</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapter 1 - Introduction to Marine Imaging</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Introduction_MarineImaging.html">1. Marine Imaging</a></li>
<li class="toctree-l1"><a class="reference internal" href="Intro_Imagery.html">2. Imagery Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="OceanImageTypes.html">3. Ocean Image Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="Introduction_AI.html">4. Artificial Intelligence in Marine Science</a></li>
<li class="toctree-l1"><a class="reference internal" href="Transfer_Learning_Marine.html">5. Transfer Learning for Marine Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="Model_Interpretability_Marine.html">6. Model Interpretability for Marine Computer Vision</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapter 2 - Introduction to Computer Vision</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Image_Annotation_CV.html">7. Image Annotation for Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="Augmentation_Manual.html">8. Image Manipulation in Python with PIL and OpenCV</a></li>
<li class="toctree-l1"><a class="reference internal" href="Augmentation_Albumentation.html">9. Creating and Augmenting Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="Introduction_Metrics.html">10. Understanding CV Metrics and Graphs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapter 3 - Computer Vision Development</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Classification_Keras.html">11. Image Classification with Keras</a></li>
<li class="toctree-l1"><a class="reference internal" href="Introduction_YOLO.html">12. Training YOLO Models: A Guide to Understanding Tasks and Modes</a></li>
<li class="toctree-l1"><a class="reference internal" href="TrainandDeployObj_YOLO.html">13. Training and Deploying Object Detection with YOLO</a></li>
<li class="toctree-l1"><a class="reference internal" href="Classification_YOLO.html">14. Ice Seal Classification using YOLOv11</a></li>
<li class="toctree-l1"><a class="reference internal" href="Introduction_Fathomnet.html">15. Introduction to FathomNet</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">16. Localizing FathomNet to a New Dataset Using YOLOv11</a></li>
<li class="toctree-l1"><a class="reference internal" href="FathomnetPullingData_YOLO.html">17. Pulling Data from Fathomnet</a></li>
<li class="toctree-l1"><a class="reference internal" href="FathomnetObjTracking_YOLO.html">18. Object and Multi-Object Tracking with Fathomnet and YOLO</a></li>
<li class="toctree-l1"><a class="reference internal" href="FathomnetObjInZone_YOLO.html">19. Object in Zone Detection with Fathomnet and YOLO</a></li>
<li class="toctree-l1"><a class="reference internal" href="Keypoint_YOLO.html">20. Keypoint Detection With YOLO</a></li>
<li class="toctree-l1"><a class="reference internal" href="InstanceSegmentation_YOLO.html">21. Instance Segmentation with YOLO</a></li>
<li class="toctree-l1"><a class="reference internal" href="ClusterSegmentation_Kmeans.html">22. K-means Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="SRGAN_Tensorflow.html">23. Image Super-Resolution and Enhancement with SRGAN in TensorFlow</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapter 4 - Synthesis Project</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Final_HFOrganization.html">24. Joining the OceanCV Hugging Face Organization and Uploading Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="Final_ModelCard.html">25. Writing a Model Card</a></li>
<li class="toctree-l1"><a class="reference internal" href="Final_StreamlitApps.html">26. Creating Streamlit Applications for YOLOv11 Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="Final_DatasetSelection.html">27. Finding Datasets for Computer Vision Projects</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="PreMIWSurvey.html">Survey Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="Introduction_CNN.html">The Math Behind Convolutional Neural Networks (CNNs)</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/atticus-carter/cv/master?urlpath=tree/book/FathomnetLocalizing_YOLO.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/atticus-carter/cv/blob/master/book/FathomnetLocalizing_YOLO.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/atticus-carter/cv" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/atticus-carter/cv/edit/main/book/FathomnetLocalizing_YOLO.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/atticus-carter/cv/issues/new?title=Issue%20on%20page%20%2Fbook/FathomnetLocalizing_YOLO.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/book/FathomnetLocalizing_YOLO.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Localizing FathomNet to a New Dataset Using YOLOv11</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">16.1. Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-fathomnet-and-mbari-s-foundational-models">16.2. Introduction to FathomNet and MBARI’s Foundational Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-preparation-and-inference">16.3. Dataset Preparation and Inference</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-initial-predictions">16.3.1. Run Initial Predictions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#localizing-annotations">16.3.2. Localizing Annotations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#localizing-the-model">16.4. Localizing the Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tracking-and-inference-parameter-adjustment">16.5. Tracking and Inference Parameter Adjustment</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#configure-and-run-tracking">16.5.1. Configure and Run Tracking</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#track-in-zone">16.6. Track in Zone</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#video-capture-initialization">16.6.1. Video Capture Initialization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#video-writer-setup">16.6.2. Video Writer Setup</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#region-selection">16.6.3. Region Selection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#object-counting-initialization">16.6.4. Object Counting Initialization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#video-processing-loop">16.6.5. Video Processing Loop</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="localizing-fathomnet-to-a-new-dataset-using-yolov11">
<h1><span class="section-number">16. </span>Localizing FathomNet to a New Dataset Using YOLOv11<a class="headerlink" href="#localizing-fathomnet-to-a-new-dataset-using-yolov11" title="Permalink to this heading">#</a></h1>
<section id="learning-objectives">
<h2><span class="section-number">16.1. </span>Learning Objectives<a class="headerlink" href="#learning-objectives" title="Permalink to this heading">#</a></h2>
<p>By the end of this lesson, you will be able to:</p>
<ol class="arabic simple">
<li><p>Understand how to adapt the FathomNet dataset to a new dataset.</p></li>
<li><p>Utilize one of MBARI’s foundational fathomnet models (MBARI 315k) for inference.</p></li>
<li><p>Train a YOLOv11 model using the localized dataset with adjusted parameters for optimal performance.</p></li>
<li><p>Experiment with prediction and tracking modes.</p></li>
</ol>
</section>
<hr class="docutils" />
<section id="introduction-to-fathomnet-and-mbari-s-foundational-models">
<h2><span class="section-number">16.2. </span>Introduction to FathomNet and MBARI’s Foundational Models<a class="headerlink" href="#introduction-to-fathomnet-and-mbari-s-foundational-models" title="Permalink to this heading">#</a></h2>
<p>FathomNet is a large dataset designed for marine imagery analysis, and MBARI has developed many models from their dataset. The two most helpful for “localizing” a new dataset are:</p>
<ol class="arabic">
<li><p><strong>Megalodon</strong>: A region of interest (ROI) detector with a single class, “object.”</p>
<p><a class="reference external" href="https://huggingface.co/FathomNet/megalodon">Megalodon Model</a></p>
</li>
<li><p><strong>MBARI 315k</strong>: A taxonomy-based object detector trained on a large-scale dataset.</p>
<p><a class="reference external" href="https://huggingface.co/FathomNet/MBARI-315k-yolov8">MBARI 315k Model</a></p>
</li>
</ol>
<p><strong>Localization</strong> in this context refers to the process of adapting a general model, like those trained on the FathomNet dataset, to work effectively on a specific dataset. This is done by utilizing the pre-trained weights from these models and fine-tuning them with new labels and annotations from your dataset. By starting with pre-trained models, significant time is saved because:</p>
<ul class="simple">
<li><p>The models already encode a large amount of knowledge about marine imagery, reducing the need for extensive initial training.</p></li>
<li><p>Localization allows the transfer of this learned information to a new dataset, which may have unique characteristics, by focusing on fine-tuning rather than training from scratch.</p></li>
</ul>
<p>These models provide a foundation for efficient training and allow researchers to quickly generate results tailored to their specific needs. Up until recently, the only starting checkpoints for localization were based on large-scale datasets like COCO, which often contain no relevant data for specific scientific domains like marine imagery. Having models like Megalodon and MBARI 315k, whose weights are already tuned to the same domain, enables significantly better performance and reduces the time required to adapt a model. This domain-specific starting point allows researchers to achieve meaningful results without needing to train entirely from scratch. For our purposes we will be using the 315K model in this activity as it has more relavence to our dataset. If your dataset is particularly distinct from the deep sea benthos, it may make more sense to start with the Megalodon model as that is what Fathomnet is primarily trained on.</p>
</section>
<hr class="docutils" />
<section id="dataset-preparation-and-inference">
<h2><span class="section-number">16.3. </span>Dataset Preparation and Inference<a class="headerlink" href="#dataset-preparation-and-inference" title="Permalink to this heading">#</a></h2>
<p>For this lesson, we will use a new dataset: a 38-minute ROV transect near a methane seep that has been compressed from its original resolution for ease of import and predictions. ROV transects are often used to survey an area and its ecosystem, and these videos are traditionally analyzed manually or qualitatively. However, these transects can often span hours of footage and require significant labor to analyze effectively.</p>
<p>To make localization practical for real-world use, instead of processing an entire dataset at once, we recommend generating a subset of videos with representative classes. This can be achieved by skimming through the dataset and identifying unique or diverse instances in the video or images. A general rule of thumb is to use approximately 20 minutes of video footage or 2000 still images that encompass a variety of classes representative of the entire dataset. For our purposes, we will be subsetting this video into every 32nd frame, providing roughly 2000 images to work with. This subset size is manageable for one person to analyze and provides a quick enough turnaround to make localization worthwhile.</p>
<p>By working with such subsets, the process becomes more efficient while still allowing for effective adaptation of the FathomNet models to the dataset.</p>
<section id="run-initial-predictions">
<h3><span class="section-number">16.3.1. </span>Run Initial Predictions<a class="headerlink" href="#run-initial-predictions" title="Permalink to this heading">#</a></h3>
<p>Use the <code class="docutils literal notranslate"><span class="pre">ultralytics</span></code> library to run predictions with both models. Passing the <code class="docutils literal notranslate"><span class="pre">save_txt=True</span></code> parameter is essential as it saves the text annotations produced in a format that is easy to import and modify:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!nvidia-smi
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!pip install ultralytics
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">cv2</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics</span><span class="w"> </span><span class="kn">import</span> <span class="n">YOLO</span>

<span class="c1"># Create a folder for the sampled frames</span>
<span class="n">subset_folder</span> <span class="o">=</span> <span class="s2">&quot;frames&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">subset_folder</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Input video file</span>
<span class="n">video_path</span> <span class="o">=</span> <span class="s2">&quot;/content/transect_compressed.mp4&quot;</span>

<span class="c1"># Sample every 32nd frame from the video</span>
<span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span>
<span class="n">total_frames</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">cap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_FRAME_COUNT</span><span class="p">))</span>
<span class="n">frame_rate</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">cap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_FPS</span><span class="p">))</span>
<span class="n">sample_rate</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">frame_count</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">while</span> <span class="n">cap</span><span class="o">.</span><span class="n">isOpened</span><span class="p">():</span>
    <span class="n">ret</span><span class="p">,</span> <span class="n">frame</span> <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">ret</span><span class="p">:</span>
        <span class="k">break</span>

    <span class="k">if</span> <span class="n">frame_count</span> <span class="o">%</span> <span class="n">sample_rate</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">frame_filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">subset_folder</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;frame_</span><span class="si">{</span><span class="n">frame_count</span><span class="si">}</span><span class="s2">.jpg&quot;</span><span class="p">)</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="n">frame_filename</span><span class="p">,</span> <span class="n">frame</span><span class="p">)</span>

    <span class="n">frame_count</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">cap</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sampled frames saved in folder: </span><span class="si">{</span><span class="n">subset_folder</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd"># Load the Megalodon model</span>
<span class="sd">megalodon_model = YOLO(&quot;https://huggingface.co/FathomNet/megalodon/resolve/main/best.pt&quot;)</span>

<span class="sd"># Run inference on the sampled frames with Megalodon</span>
<span class="sd">megalodon_model.predict(</span>
<span class="sd">    source=subset_folder,</span>
<span class="sd">    save_txt=True,</span>
<span class="sd">    imgsz=1024,</span>
<span class="sd">    conf=0.10,</span>
<span class="sd">    iou=0.5,</span>
<span class="sd">    agnostic_nms=True</span>
<span class="sd">)</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="c1"># Load the MBARI 315k model</span>
<span class="n">mbari_model</span> <span class="o">=</span> <span class="n">YOLO</span><span class="p">(</span><span class="s2">&quot;https://huggingface.co/FathomNet/MBARI-315k-yolov8/resolve/main/mbari_315k_yolov8.pt&quot;</span><span class="p">)</span>

<span class="c1"># Run inference on the sampled frames with MBARI 315k</span>
<span class="n">mbari_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
    <span class="n">source</span><span class="o">=</span><span class="n">subset_folder</span><span class="p">,</span>
    <span class="n">save_txt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">imgsz</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">conf</span><span class="o">=</span><span class="mf">0.10</span><span class="p">,</span>
    <span class="n">iou</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">agnostic_nms</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="localizing-annotations">
<h3><span class="section-number">16.3.2. </span>Localizing Annotations<a class="headerlink" href="#localizing-annotations" title="Permalink to this heading">#</a></h3>
<p>Next, we want to work on localizing the predicted annotations to our class nomenclature. For this example, we will be taking the annotations given by the 315k model in taxonomic format and collapsing them into broader categories, referred to as ecological tiers. This step is done to speed up the activity and act as a proof of concept. However, always remember to consider your research question and the degree of specificity you need for your classes.</p>
<p>Below is a guide for the four representative tiers present in this transect. This is not an exhaustive list of taxa that fit these descriptions but rather a representative sample. The four tiers are:</p>
<p>Sessile Epifauna: Organisms that are attached to the substrate, such as anemones and sponges.</p>
<p>Motile Epifauna: Organisms capable of moving that primarily live on the substrate, such as sea urchins, cucumbers and  stars.</p>
<p>Demersal: Organisms that live near or on the seafloor but are capable of swimming, like benthic fish.</p>
<p>Planktonic: Organisms that drift in the water column, such as euphasiids and other plankton.</p>
<figure class="align-default" id="broad-classes">
<img alt="../_images/Epifauna.png" src="../_images/Epifauna.png" />
<figcaption>
<p><span class="caption-number">Fig. 16.1 </span><span class="caption-text">OOI/UW/NSF Carter 2025</span><a class="headerlink" href="#broad-classes" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>To proceed:</p>
<ol class="arabic simple">
<li><p>Go into an annotation manager like Roboflow and upload the FathomNet labelmap along with your dataset. (The labelmap can be accessed on the <a class="reference external" href="https://huggingface.co/FathomNet/MBARI-315k-yolov8">315 huggingface</a> or can be automatically zipped with your dataset if you run the cell below.)</p></li>
<li><p>Luckily, the FathomNet model did most of the heavy lifting and should have predicted relatively close to the actual species. For each class, go through and review images with that class. As you go, mark down which of the four tiers each class best fits into. After reviewing all classes, bulk reassign the classes into the four tiers. Then, go through and check if anything was missed.</p></li>
<li><p>Once complete, export your dataset as a ZIP file in YOLOv11 format for further processing in the colab environment. Ensure that your splits are balanced per class before exporting! A test set will not be necessary.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">zipfile</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">urllib.request</span>

<span class="k">def</span><span class="w"> </span><span class="nf">zip_folders_and_file</span><span class="p">(</span><span class="n">folder_paths</span><span class="p">,</span> <span class="n">additional_file_url</span><span class="p">,</span> <span class="n">output_filename</span><span class="p">):</span>

    <span class="n">additional_file_path</span> <span class="o">=</span> <span class="s2">&quot;config.yaml&quot;</span>
    <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">additional_file_url</span><span class="p">,</span> <span class="n">additional_file_path</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">output_filename</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZIP_DEFLATED</span><span class="p">)</span> <span class="k">as</span> <span class="n">zipf</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">folder</span> <span class="ow">in</span> <span class="n">folder_paths</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">root</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">files</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="n">folder</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
                    <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>
                    <span class="n">arcname</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">relpath</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">folder</span><span class="p">)</span>
                    <span class="n">zipf</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">arcname</span><span class="p">)</span>
        <span class="n">zipf</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">additional_file_path</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">additional_file_path</span><span class="p">))</span>

<span class="n">folders_to_zip</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;/content/frames&quot;</span><span class="p">,</span> <span class="s2">&quot;/content/runs/detect/predict/labels&quot;</span><span class="p">]</span>
<span class="n">additional_file_url</span> <span class="o">=</span> <span class="s2">&quot;https://huggingface.co/FathomNet/MBARI-315k-yolov8/resolve/main/config.yaml?download=true&quot;</span>
<span class="n">output_zip</span> <span class="o">=</span> <span class="s2">&quot;/content/315k.zip&quot;</span>
<span class="n">zip_folders_and_file</span><span class="p">(</span><span class="n">folders_to_zip</span><span class="p">,</span> <span class="n">additional_file_url</span><span class="p">,</span> <span class="n">output_zip</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">google.colab</span><span class="w"> </span><span class="kn">import</span> <span class="n">files</span>

<span class="n">files</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;/content/315k.zip&#39;</span><span class="p">)</span>  <span class="c1"># Download 315k.zip</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
    async function download(id, filename, size) {
      if (!google.colab.kernel.accessAllowed) {
        return;
      }
      const div = document.createElement('div');
      const label = document.createElement('label');
      label.textContent = `Downloading "${filename}": `;
      div.appendChild(label);
      const progress = document.createElement('progress');
      progress.max = size;
      div.appendChild(progress);
      document.body.appendChild(div);

      const buffers = [];
      let downloaded = 0;

      const channel = await google.colab.kernel.comms.open(id);
      // Send a message to notify the kernel that we're ready.
      channel.send({})

      for await (const message of channel.messages) {
        // Send a message to notify the kernel that we're ready.
        channel.send({})
        if (message.buffers) {
          for (const buffer of message.buffers) {
            buffers.push(buffer);
            downloaded += buffer.byteLength;
            progress.value = downloaded;
          }
        }
      }
      const blob = new Blob(buffers, {type: 'application/binary'});
      const a = document.createElement('a');
      a.href = window.URL.createObjectURL(blob);
      a.download = filename;
      div.appendChild(a);
      a.click();
      div.remove();
    }
  </script><script type="application/javascript">download("download_80f8639b-7605-4bff-9d00-e1fb48a56d04", "315k.zip", 180968758)</script><script type="application/javascript">
    async function download(id, filename, size) {
      if (!google.colab.kernel.accessAllowed) {
        return;
      }
      const div = document.createElement('div');
      const label = document.createElement('label');
      label.textContent = `Downloading "${filename}": `;
      div.appendChild(label);
      const progress = document.createElement('progress');
      progress.max = size;
      div.appendChild(progress);
      document.body.appendChild(div);

      const buffers = [];
      let downloaded = 0;

      const channel = await google.colab.kernel.comms.open(id);
      // Send a message to notify the kernel that we're ready.
      channel.send({})

      for await (const message of channel.messages) {
        // Send a message to notify the kernel that we're ready.
        channel.send({})
        if (message.buffers) {
          for (const buffer of message.buffers) {
            buffers.push(buffer);
            downloaded += buffer.byteLength;
            progress.value = downloaded;
          }
        }
      }
      const blob = new Blob(buffers, {type: 'application/binary'});
      const a = document.createElement('a');
      a.href = window.URL.createObjectURL(blob);
      a.download = filename;
      div.appendChild(a);
      a.click();
      div.remove();
    }
  </script><script type="application/javascript">download("download_5392463f-2c59-444c-bf44-3d3c07b25b62", "megalodon.zip", 181058798)</script></div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="localizing-the-model">
<h2><span class="section-number">16.4. </span>Localizing the Model<a class="headerlink" href="#localizing-the-model" title="Permalink to this heading">#</a></h2>
<p>Now that you have a finalized four-class dataset, it’s time to train a model. Use MBARI 315k as a checkpoint to import useful weights and override the old class labels with your new class labels to create a robust model tailored to your dataset.</p>
<p>For this training, we will select the following parameters:</p>
<p>Data Configuration: data.yaml, which includes the paths to your train and validation datasets.</p>
<p>Epochs: Set to 100 to ensure sufficient learning while avoiding overfitting.</p>
<p>Image Size: 1024 to balance detail and computational efficiency.</p>
<p>Patience: 10, to allow the model to terminate training early if no improvement is seen.</p>
<p>Plots: Enabled (plots=True) to generate visualizations of the training progress.</p>
<p>Below is the code to initiate training:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics</span><span class="w"> </span><span class="kn">import</span> <span class="n">YOLO</span>

<span class="c1"># Load a pretrained model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">YOLO</span><span class="p">(</span><span class="s2">&quot;mbari_315k_yolov8.pt&quot;</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="s2">&quot;data.yaml&quot;</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">imgsz</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">plots</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="tracking-and-inference-parameter-adjustment">
<h2><span class="section-number">16.5. </span>Tracking and Inference Parameter Adjustment<a class="headerlink" href="#tracking-and-inference-parameter-adjustment" title="Permalink to this heading">#</a></h2>
<p>To optimize the model, you will need to experiment with parameter combinations and evaluate performance by creating and analyzing four separate tracking videos.</p>
<section id="configure-and-run-tracking">
<h3><span class="section-number">16.5.1. </span>Configure and Run Tracking<a class="headerlink" href="#configure-and-run-tracking" title="Permalink to this heading">#</a></h3>
<p>Use the <code class="docutils literal notranslate"><span class="pre">ultralytics</span></code> library to configure tracking parameters.  You can create four separate videos by changing the following parameters:</p>
<ol class="arabic simple">
<li><p><strong>IoU Threshold</strong></p></li>
<li><p><strong>Confidence Threshold</strong></p></li>
<li><p><strong>Agnostic NMS</strong></p></li>
<li><p><strong>Tracker Type</strong></p></li>
</ol>
<p>Here is an example setup to guide you:
Feel free to change add or delete any of the configs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics</span><span class="w"> </span><span class="kn">import</span> <span class="n">YOLO</span>

<span class="c1"># Initialize the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">YOLO</span><span class="p">(</span><span class="s2">&quot;/PATH/TO/YOUR/best.pt&quot;</span><span class="p">)</span>

<span class="c1"># Define a list of tracking configurations</span>
<span class="n">tracking_configs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s2">&quot;conf&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s2">&quot;iou&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s2">&quot;agnostic_nms&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;tracker&quot;</span><span class="p">:</span> <span class="s2">&quot;bytetrack.yaml&quot;</span><span class="p">},</span>  <span class="c1"># Default settings</span>
    <span class="p">{</span><span class="s2">&quot;conf&quot;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span> <span class="s2">&quot;iou&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s2">&quot;agnostic_nms&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;tracker&quot;</span><span class="p">:</span> <span class="s2">&quot;bytetrack.yaml&quot;</span><span class="p">},</span>   <span class="c1"># High confidence, agnostic NMS</span>
    <span class="p">{</span><span class="s2">&quot;conf&quot;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span> <span class="s2">&quot;iou&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s2">&quot;agnostic_nms&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;tracker&quot;</span><span class="p">:</span> <span class="s2">&quot;sort.yaml&quot;</span><span class="p">},</span>       <span class="c1"># Low confidence, SORT tracker</span>
    <span class="p">{</span><span class="s2">&quot;conf&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s2">&quot;iou&quot;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span> <span class="s2">&quot;agnostic_nms&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;tracker&quot;</span><span class="p">:</span> <span class="s2">&quot;sort.yaml&quot;</span><span class="p">}</span>         <span class="c1"># High IoU, SORT tracker</span>
<span class="p">]</span>

<span class="c1"># Common settings</span>
<span class="n">common_settings</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;content/transect_compressed.mp4&quot;</span><span class="p">,</span>
    <span class="s2">&quot;save_txt&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="s2">&quot;imgsz&quot;</span><span class="p">:</span> <span class="mi">1024</span>
<span class="p">}</span>

<span class="c1"># Run tracking for each configuration</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">config</span> <span class="ow">in</span> <span class="n">tracking_configs</span><span class="p">:</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="o">**</span><span class="n">common_settings</span><span class="p">,</span> <span class="o">**</span><span class="n">config</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="track-in-zone">
<h2><span class="section-number">16.6. </span>Track in Zone<a class="headerlink" href="#track-in-zone" title="Permalink to this heading">#</a></h2>
<p>Tracking objects within a specific zone is crucial for analyzing ROV and other transects where the objects you are interested in pass by the camera. By focusing on a defined region, researchers can ensure accurate detection and counting of marine organisms or features while minimizing noise from irrelevant areas. This method helps standardize data collection, enabling more reliable comparisons across different transects and improving ecological assessments of underwater environments.</p>
<section id="video-capture-initialization">
<h3><span class="section-number">16.6.1. </span>Video Capture Initialization<a class="headerlink" href="#video-capture-initialization" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="s2">&quot;/content/transect_compressed.mp4&quot;</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">cap</span><span class="o">.</span><span class="n">isOpened</span><span class="p">(),</span> <span class="s2">&quot;Error reading video file&quot;</span>
<span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">fps</span> <span class="o">=</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">cap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_FRAME_WIDTH</span><span class="p">,</span>
                                       <span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_FRAME_HEIGHT</span><span class="p">,</span>
                                       <span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_FPS</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>This block initializes the video capture from the specified file (transect_compressed.mp4). It verifies that the video file is successfully opened and retrieves the video’s width, height, and frames per second (fps) using OpenCV properties.</p>
</section>
<section id="video-writer-setup">
<h3><span class="section-number">16.6.2. </span>Video Writer Setup<a class="headerlink" href="#video-writer-setup" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">video_writer</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoWriter</span><span class="p">(</span><span class="s2">&quot;counting.avi&quot;</span><span class="p">,</span>
                               <span class="n">cv2</span><span class="o">.</span><span class="n">VideoWriter_fourcc</span><span class="p">(</span><span class="o">*</span><span class="s2">&quot;mp4v&quot;</span><span class="p">),</span>
                               <span class="n">fps</span><span class="p">,</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>This section sets up a video writer to save the processed frames into a new output file (counting.avi). It uses the MP4V codec for encoding and ensures the output video has the same fps and dimensions as the original.</p>
</section>
<section id="region-selection">
<h3><span class="section-number">16.6.3. </span>Region Selection<a class="headerlink" href="#region-selection" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">region_points</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">576</span><span class="p">),</span> <span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">576</span><span class="p">),</span> <span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">768</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">768</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<p>This defines a rectangular region of interest (ROI) in the video, given as four coordinate points. This region is used to track and count objects only within the specified area. For our usecase the ROI is set to the bottom quarter of the video to count animals as the ROV passes above them.</p>
</section>
<section id="object-counting-initialization">
<h3><span class="section-number">16.6.4. </span>Object Counting Initialization<a class="headerlink" href="#object-counting-initialization" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">counter</span> <span class="o">=</span> <span class="n">solutions</span><span class="o">.</span><span class="n">ObjectCounter</span><span class="p">(</span>
    <span class="n">region</span><span class="o">=</span><span class="n">region_points</span><span class="p">,</span>  
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;/content/best.pt&quot;</span><span class="p">,</span>
    <span class="n">save_txt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">conf</span><span class="o">=</span><span class="mf">0.10</span><span class="p">,</span>
    <span class="n">iou</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">agnostic_nms</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>An object counter is initialized using a trained model (<a class="reference external" href="http://best.pt">best.pt</a>). The parameters include:</p>
<p>region=region_points: Specifies the defined tracking zone.</p>
<p>save_txt=True: Saves the detection results to a text file.</p>
<p>conf=0.10: Sets a confidence threshold of 10% for object detection.</p>
<p>iou=0.5: Uses a 50% Intersection Over Union (IoU) threshold to refine detections.</p>
<p>agnostic_nms=True: Enables class-agnostic non-maximum suppression for overlapping detections.</p>
</section>
<section id="video-processing-loop">
<h3><span class="section-number">16.6.5. </span>Video Processing Loop<a class="headerlink" href="#video-processing-loop" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">while</span> <span class="n">cap</span><span class="o">.</span><span class="n">isOpened</span><span class="p">():</span>
    <span class="n">success</span><span class="p">,</span> <span class="n">im0</span> <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">success</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video frame is empty or video processing has been successfully completed.&quot;</span><span class="p">)</span>
        <span class="k">break</span>
    <span class="n">im0</span> <span class="o">=</span> <span class="n">counter</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">im0</span><span class="p">)</span>  <span class="c1"># count the objects</span>
    <span class="n">video_writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">im0</span><span class="p">)</span>   <span class="c1"># write the video frames</span>

<span class="n">cap</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>   <span class="c1"># Release the capture</span>
<span class="n">video_writer</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>This loop processes each frame from the video:</p>
<p>Reads a frame from the video.
If no frame is available, it prints a message and stops processing.
Runs object counting on the frame using counter.count(im0).
Writes the processed frame to the output video.
Releases the video resources after processing all frames and closes all OpenCV windows.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./book"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Introduction_Fathomnet.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">15. </span>Introduction to FathomNet</p>
      </div>
    </a>
    <a class="right-next"
       href="FathomnetPullingData_YOLO.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">17. </span>Pulling Data from Fathomnet</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">16.1. Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-fathomnet-and-mbari-s-foundational-models">16.2. Introduction to FathomNet and MBARI’s Foundational Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-preparation-and-inference">16.3. Dataset Preparation and Inference</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-initial-predictions">16.3.1. Run Initial Predictions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#localizing-annotations">16.3.2. Localizing Annotations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#localizing-the-model">16.4. Localizing the Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tracking-and-inference-parameter-adjustment">16.5. Tracking and Inference Parameter Adjustment</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#configure-and-run-tracking">16.5.1. Configure and Run Tracking</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#track-in-zone">16.6. Track in Zone</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#video-capture-initialization">16.6.1. Video Capture Initialization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#video-writer-setup">16.6.2. Video Writer Setup</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#region-selection">16.6.3. Region Selection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#object-counting-initialization">16.6.4. Object Counting Initialization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#video-processing-loop">16.6.5. Video Processing Loop</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Atticus Carter
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>